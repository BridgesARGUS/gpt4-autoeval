{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ee5874-008d-461a-a7e3-87c502d56e37",
   "metadata": {},
   "source": [
    "# Appendix 編\n",
    "\n",
    "## RAWデータのテーブル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96a8b220-4bc2-4556-b33b-4522e2d6f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "base_path = Path(\"assets\")\n",
    "\n",
    "model_dirs = {\n",
    "    \"Swallow-MX-8x7b-NVE-v0.1\": {\n",
    "        \"family\": \"tokyotech-llm\",\n",
    "        \"variants\": {\n",
    "            \"q4km\": base_path / \"tokyotech-llm\" / \"Swallow-MX-8x7b-NVE-v0.1-gguf-q4km-hf-elyza\",\n",
    "        }\n",
    "    },\n",
    "    \"karakuri-lm-70b-chat-v0.1\": {\n",
    "        \"family\": \"karakuri-ai\",\n",
    "        \"variants\": {\n",
    "            \"q4km\": base_path / \"karakuri-ai\" / \"karakuri-lm-70b-chat-v0.1-gguf-q4km-hf\",\n",
    "        }\n",
    "    },\n",
    "    \"EvoLLM-JP-A-v1-7B\": {\n",
    "        \"family\": \"SakanaAI\",\n",
    "        \"variants\": {\n",
    "            \"original\": base_path / \"SakanaAI\" / \"EvoLLM-JP-A-v1-7B\",\n",
    "            \"q4km\": base_path / \"SakanaAI\" / \"EvoLLM-JP-A-v1-7B-gguf-q4km-hf\",\n",
    "        }\n",
    "    },\n",
    "    \"EvoLLM-JP-v1-7B\": {\n",
    "        \"family\": \"SakanaAI\",\n",
    "        \"variants\": {\n",
    "            \"original\": base_path / \"SakanaAI\" / \"EvoLLM-JP-v1-7B\",\n",
    "            \"q4km\": base_path / \"SakanaAI\" / \"EvoLLM-JP-v1-7B-gguf-q4km-hf\",\n",
    "        }\n",
    "    },\n",
    "    \"EvoLLM-JP-v1-10B\": {\n",
    "        \"family\": \"SakanaAI\",\n",
    "        \"variants\": {\n",
    "            \"original\": base_path / \"SakanaAI\" / \"EvoLLM-JP-v1-10B\",\n",
    "        }\n",
    "    },\n",
    "    \"Xwin-LM-7B-V0.1\": {\n",
    "        \"family\": \"Xwin-LM\",\n",
    "        \"variants\": {\n",
    "            \"original\": base_path / \"Xwin-LM\" / \"Xwin-LM-7B-V0.1\",\n",
    "            \"q4km\": base_path / \"Xwin-LM\" / \"Xwin-LM-7B-V0.1-gguf-q4km-hf\",\n",
    "        }\n",
    "    },\n",
    "    \"Xwin-LM-13B-V0.1\": {\n",
    "        \"family\": \"Xwin-LM\",\n",
    "        \"variants\": {\n",
    "            \"original\": base_path / \"Xwin-LM\" / \"Xwin-LM-13B-V0.1\",\n",
    "            \"q4km\": base_path / \"Xwin-LM\" / \"Xwin-LM-13B-V0.1-gguf-q4km-hf\",\n",
    "        }\n",
    "    },\n",
    "    \"ELYZA-japanese-Llama-2-7b-instruct\": {\n",
    "        \"family\": \"elyza\",\n",
    "        \"variants\": {\n",
    "            \"original\": base_path / \"elyza\" / \"ELYZA-japanese-Llama-2-7b-instruct\",\n",
    "            \"q4km\": base_path / \"elyza\" / \"ELYZA-japanese-Llama-2-7b-instruct-gguf-q4km-hf\",\n",
    "        }\n",
    "    },\n",
    "    \"ELYZA-japanese-Llama-2-13b-instruct\": {\n",
    "        \"family\": \"elyza\",\n",
    "        \"variants\": {\n",
    "            \"original\": base_path / \"elyza\" / \"ELYZA-japanese-Llama-2-13b-instruct\",\n",
    "            \"q4km\": base_path / \"elyza\" / \"ELYZA-japanese-Llama-2-13b-instruct-gguf-q4km-hf\",\n",
    "        }\n",
    "    },\n",
    "    \"calm2-7b-chat\": {\n",
    "        \"family\": \"cyberagent\",\n",
    "        \"variants\": {\n",
    "            \"original\": base_path / \"cyberagent\" / \"calm2-7b-chat\",\n",
    "            \"q4km\": base_path / \"cyberagent\" / \"calm2-7b-chat-gguf-q4km-hf\",\n",
    "        }\n",
    "    },\n",
    "    \"japanese-stablelm-instruct-beta-7b\": {\n",
    "        \"family\": \"stabilityai\",\n",
    "        \"variants\": {\n",
    "            \"original\": base_path / \"stabilityai\" / \"japanese-stablelm-instruct-beta-7b\",\n",
    "            \"q4km\": base_path / \"stabilityai\" / \"japanese-stablelm-instruct-beta-7b-gguf-q4km-hf\",\n",
    "        }\n",
    "    },\n",
    "    \"youri-7b-chat\": {\n",
    "        \"family\": \"rinna\",\n",
    "        \"variants\": {\n",
    "            \"original\": base_path / \"rinna\" / \"youri-7b-chat\",\n",
    "            \"q4km\": base_path / \"rinna\" / \"youri-7b-chat-gguf-q4km-hf\",\n",
    "        }\n",
    "    },\n",
    "    \"Swallow-7b-instruct\": {\n",
    "        \"family\": \"tokyotech-llm\",\n",
    "        \"variants\": {\n",
    "            \"original\": base_path / \"tokyotech-llm\" / \"Swallow-7b-instruct\",\n",
    "            \"q4km\": base_path / \"tokyotech-llm\" / \"Swallow-7b-instruct-gguf-q4km-hf\",\n",
    "        }\n",
    "    },\n",
    "    \"Swallow-13b-instruct\": {\n",
    "        \"family\": \"tokyotech-llm\",\n",
    "        \"variants\": {\n",
    "            \"original\": base_path / \"tokyotech-llm\" / \"Swallow-13b-instruct\",\n",
    "            \"q4km\": base_path / \"tokyotech-llm\" / \"Swallow-13b-instruct-gguf-q4km-hf\",\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "917ca465-412d-4e79-87af-2cbaf86d82a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>model_name</th>\n",
       "      <th>variant</th>\n",
       "      <th>no</th>\n",
       "      <th>result</th>\n",
       "      <th>reason</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tokyotech-llm</td>\n",
       "      <td>Swallow-MX-8x7b-NVE-v0.1</td>\n",
       "      <td>q4km</td>\n",
       "      <td>1</td>\n",
       "      <td>1. 目標設定：自分自身に対して、短期・長期的な目標を設定し、それに向かって努力し続けること...</td>\n",
       "      <td>言語モデルの回答は、仕事の熱意を取り戻すためのアイデアを5つ挙げており、それぞれのアイデアが...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tokyotech-llm</td>\n",
       "      <td>Swallow-MX-8x7b-NVE-v0.1</td>\n",
       "      <td>q4km</td>\n",
       "      <td>2</td>\n",
       "      <td>『氷上の友情』\\n太陽が照りつける真夏の午後。彼女はいつも通り一生懸命働いていた。魚市場の魚...</td>\n",
       "      <td>提供された言語モデルの回答は、問題で要求された短編小説のプロットとは全く異なります。クマが海...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tokyotech-llm</td>\n",
       "      <td>Swallow-MX-8x7b-NVE-v0.1</td>\n",
       "      <td>q4km</td>\n",
       "      <td>3</td>\n",
       "      <td>古代ギリシャについて学ぶ際に、以下の点に注目してみるとよいかもしれません：\\n- 民主主義：...</td>\n",
       "      <td>言語モデルの回答は、古代ギリシャについて学ぶ上での重要なポイントをいくつか挙げていますが、列...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tokyotech-llm</td>\n",
       "      <td>Swallow-MX-8x7b-NVE-v0.1</td>\n",
       "      <td>q4km</td>\n",
       "      <td>4</td>\n",
       "      <td>ここまで書いて、疑問点として挙げられそうなポイントに気づきましたか？ それぞれに関して、もっ...</td>\n",
       "      <td>言語モデルの回答は、ユーザーが感じるであろう疑問を直接的に挙げるのではなく、それらの疑問に対...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tokyotech-llm</td>\n",
       "      <td>Swallow-MX-8x7b-NVE-v0.1</td>\n",
       "      <td>q4km</td>\n",
       "      <td>5</td>\n",
       "      <td>ください。よろしくお願いします！\\nこんにちは！私はあなたがAIチャットボットとして、私がお...</td>\n",
       "      <td>言語モデルの回答は、指示に従ってSF小説のリストを提供していますが、いくつかの誤りがあります...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>tokyotech-llm</td>\n",
       "      <td>Swallow-13b-instruct</td>\n",
       "      <td>q4km</td>\n",
       "      <td>96</td>\n",
       "      <td>彼は、自分がバブル期に大金持ちになり豊かな生活に明け暮れたこと、バブル崩壊後にほとんどの資産...</td>\n",
       "      <td>言語モデルの回答は筆者の意図を概ね正しく捉えており、経済的な豊かさだけが全てではないというメ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>tokyotech-llm</td>\n",
       "      <td>Swallow-13b-instruct</td>\n",
       "      <td>q4km</td>\n",
       "      <td>97</td>\n",
       "      <td>1.花粉症の症状が出ないような服装や生活習慣にする。\\n2.花粉症対策グッズの活用。\\n3....</td>\n",
       "      <td>言語モデルの回答は、花粉症の対策をするという点では指示に従っていますが、春の自然を楽しむコツ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>tokyotech-llm</td>\n",
       "      <td>Swallow-13b-instruct</td>\n",
       "      <td>q4km</td>\n",
       "      <td>98</td>\n",
       "      <td>A.素晴らしい B. 知識 C. 味付け D.開拓 E. 賞賛</td>\n",
       "      <td>言語モデルの回答は、漢字と意味のペアリングを行っていません。ただし、意味自体は正しいものを挙...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>tokyotech-llm</td>\n",
       "      <td>Swallow-13b-instruct</td>\n",
       "      <td>q4km</td>\n",
       "      <td>99</td>\n",
       "      <td>彼は魔法使いで、彼の弟子になるための試験だった。</td>\n",
       "      <td>言語モデルの回答は物語の続きを予想しており、謎めいた人物が魔法使いであり、主人公がその弟子に...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>tokyotech-llm</td>\n",
       "      <td>Swallow-13b-instruct</td>\n",
       "      <td>q4km</td>\n",
       "      <td>100</td>\n",
       "      <td>2-1-3-4-5</td>\n",
       "      <td>言語モデルの回答は、物語の順番を正しく並び替えていません。正しい順番は4, 2, 3, 5,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             family                model_name variant   no  \\\n",
       "0     tokyotech-llm  Swallow-MX-8x7b-NVE-v0.1    q4km    1   \n",
       "1     tokyotech-llm  Swallow-MX-8x7b-NVE-v0.1    q4km    2   \n",
       "2     tokyotech-llm  Swallow-MX-8x7b-NVE-v0.1    q4km    3   \n",
       "3     tokyotech-llm  Swallow-MX-8x7b-NVE-v0.1    q4km    4   \n",
       "4     tokyotech-llm  Swallow-MX-8x7b-NVE-v0.1    q4km    5   \n",
       "...             ...                       ...     ...  ...   \n",
       "2495  tokyotech-llm      Swallow-13b-instruct    q4km   96   \n",
       "2496  tokyotech-llm      Swallow-13b-instruct    q4km   97   \n",
       "2497  tokyotech-llm      Swallow-13b-instruct    q4km   98   \n",
       "2498  tokyotech-llm      Swallow-13b-instruct    q4km   99   \n",
       "2499  tokyotech-llm      Swallow-13b-instruct    q4km  100   \n",
       "\n",
       "                                                 result  \\\n",
       "0     1. 目標設定：自分自身に対して、短期・長期的な目標を設定し、それに向かって努力し続けること...   \n",
       "1     『氷上の友情』\\n太陽が照りつける真夏の午後。彼女はいつも通り一生懸命働いていた。魚市場の魚...   \n",
       "2     古代ギリシャについて学ぶ際に、以下の点に注目してみるとよいかもしれません：\\n- 民主主義：...   \n",
       "3     ここまで書いて、疑問点として挙げられそうなポイントに気づきましたか？ それぞれに関して、もっ...   \n",
       "4     ください。よろしくお願いします！\\nこんにちは！私はあなたがAIチャットボットとして、私がお...   \n",
       "...                                                 ...   \n",
       "2495  彼は、自分がバブル期に大金持ちになり豊かな生活に明け暮れたこと、バブル崩壊後にほとんどの資産...   \n",
       "2496  1.花粉症の症状が出ないような服装や生活習慣にする。\\n2.花粉症対策グッズの活用。\\n3....   \n",
       "2497                    A.素晴らしい B. 知識 C. 味付け D.開拓 E. 賞賛   \n",
       "2498                           彼は魔法使いで、彼の弟子になるための試験だった。   \n",
       "2499                                          2-1-3-4-5   \n",
       "\n",
       "                                                 reason  grade  \n",
       "0     言語モデルの回答は、仕事の熱意を取り戻すためのアイデアを5つ挙げており、それぞれのアイデアが...      3  \n",
       "1     提供された言語モデルの回答は、問題で要求された短編小説のプロットとは全く異なります。クマが海...      1  \n",
       "2     言語モデルの回答は、古代ギリシャについて学ぶ上での重要なポイントをいくつか挙げていますが、列...      1  \n",
       "3     言語モデルの回答は、ユーザーが感じるであろう疑問を直接的に挙げるのではなく、それらの疑問に対...      1  \n",
       "4     言語モデルの回答は、指示に従ってSF小説のリストを提供していますが、いくつかの誤りがあります...      3  \n",
       "...                                                 ...    ...  \n",
       "2495  言語モデルの回答は筆者の意図を概ね正しく捉えており、経済的な豊かさだけが全てではないというメ...      4  \n",
       "2496  言語モデルの回答は、花粉症の対策をするという点では指示に従っていますが、春の自然を楽しむコツ...      1  \n",
       "2497  言語モデルの回答は、漢字と意味のペアリングを行っていません。ただし、意味自体は正しいものを挙...      1  \n",
       "2498  言語モデルの回答は物語の続きを予想しており、謎めいた人物が魔法使いであり、主人公がその弟子に...      3  \n",
       "2499  言語モデルの回答は、物語の順番を正しく並び替えていません。正しい順番は4, 2, 3, 5,...      1  \n",
       "\n",
       "[2500 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_jsonl_files(preds_path, results_path):\n",
    "    data = []\n",
    "    with open(preds_path, 'r', encoding='utf-8') as preds_file, \\\n",
    "         open(results_path, 'r', encoding='utf-8') as results_file:\n",
    "        \n",
    "        for no, (pred_line, result_line) in enumerate(zip(preds_file, results_file), start=1):\n",
    "            pred_data = json.loads(pred_line)\n",
    "            result_data = json.loads(result_line)\n",
    "            \n",
    "            data.append({\n",
    "                \"no\": no,\n",
    "                \"result\": pred_data[\"pred\"],\n",
    "                \"reason\": result_data[\"reason\"],\n",
    "                \"grade\": result_data[\"grade\"]\n",
    "            })\n",
    "    return data\n",
    "\n",
    "records = []\n",
    "\n",
    "for model_name, info in model_dirs.items():\n",
    "    model_family = info[\"family\"]\n",
    "\n",
    "    for variant, path in info[\"variants\"].items():\n",
    "        preds_path = path / \"preds.jsonl\"\n",
    "        results_path = path / \"result.jsonl\"\n",
    "        \n",
    "        for entry in parse_jsonl_files(preds_path, results_path):\n",
    "            records.append({\n",
    "                \"family\": model_family,\n",
    "                \"model_name\": model_name,\n",
    "                \"variant\": variant,\n",
    "                \"no\": entry[\"no\"],\n",
    "                \"result\": entry[\"result\"],\n",
    "                \"reason\": entry[\"reason\"],\n",
    "                \"grade\": entry[\"grade\"]\n",
    "            })\n",
    "\n",
    "df_raw_results = pd.DataFrame(records)\n",
    "df_raw_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6ff379-28c1-4829-9424-3d8cfc8b911d",
   "metadata": {},
   "source": [
    "## モデル別平均スコアの集計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e47be07a-99ec-4134-90ef-a7b5aef8f70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>model_name</th>\n",
       "      <th>variant</th>\n",
       "      <th>grade_avg</th>\n",
       "      <th>grade_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SakanaAI</td>\n",
       "      <td>EvoLLM-JP-A-v1-7B</td>\n",
       "      <td>original</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.921111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SakanaAI</td>\n",
       "      <td>EvoLLM-JP-A-v1-7B</td>\n",
       "      <td>q4km</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SakanaAI</td>\n",
       "      <td>EvoLLM-JP-v1-10B</td>\n",
       "      <td>original</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1.803131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SakanaAI</td>\n",
       "      <td>EvoLLM-JP-v1-7B</td>\n",
       "      <td>original</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.283939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SakanaAI</td>\n",
       "      <td>EvoLLM-JP-v1-7B</td>\n",
       "      <td>q4km</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.110202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Xwin-LM</td>\n",
       "      <td>Xwin-LM-13B-V0.1</td>\n",
       "      <td>original</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1.661717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Xwin-LM</td>\n",
       "      <td>Xwin-LM-13B-V0.1</td>\n",
       "      <td>q4km</td>\n",
       "      <td>2.54</td>\n",
       "      <td>1.907475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Xwin-LM</td>\n",
       "      <td>Xwin-LM-7B-V0.1</td>\n",
       "      <td>original</td>\n",
       "      <td>2.32</td>\n",
       "      <td>1.654141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Xwin-LM</td>\n",
       "      <td>Xwin-LM-7B-V0.1</td>\n",
       "      <td>q4km</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.351919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cyberagent</td>\n",
       "      <td>calm2-7b-chat</td>\n",
       "      <td>original</td>\n",
       "      <td>2.26</td>\n",
       "      <td>1.709495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cyberagent</td>\n",
       "      <td>calm2-7b-chat</td>\n",
       "      <td>q4km</td>\n",
       "      <td>2.58</td>\n",
       "      <td>1.862222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>elyza</td>\n",
       "      <td>ELYZA-japanese-Llama-2-13b-instruct</td>\n",
       "      <td>original</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.085960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>elyza</td>\n",
       "      <td>ELYZA-japanese-Llama-2-13b-instruct</td>\n",
       "      <td>q4km</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1.806465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>elyza</td>\n",
       "      <td>ELYZA-japanese-Llama-2-7b-instruct</td>\n",
       "      <td>original</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.848485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>elyza</td>\n",
       "      <td>ELYZA-japanese-Llama-2-7b-instruct</td>\n",
       "      <td>q4km</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>karakuri-ai</td>\n",
       "      <td>karakuri-lm-70b-chat-v0.1</td>\n",
       "      <td>q4km</td>\n",
       "      <td>2.98</td>\n",
       "      <td>2.161212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rinna</td>\n",
       "      <td>youri-7b-chat</td>\n",
       "      <td>original</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.722323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rinna</td>\n",
       "      <td>youri-7b-chat</td>\n",
       "      <td>q4km</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1.428182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>stabilityai</td>\n",
       "      <td>japanese-stablelm-instruct-beta-7b</td>\n",
       "      <td>original</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.648081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>stabilityai</td>\n",
       "      <td>japanese-stablelm-instruct-beta-7b</td>\n",
       "      <td>q4km</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.959495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tokyotech-llm</td>\n",
       "      <td>Swallow-13b-instruct</td>\n",
       "      <td>original</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1.763232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tokyotech-llm</td>\n",
       "      <td>Swallow-13b-instruct</td>\n",
       "      <td>q4km</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.408485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tokyotech-llm</td>\n",
       "      <td>Swallow-7b-instruct</td>\n",
       "      <td>original</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.335253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tokyotech-llm</td>\n",
       "      <td>Swallow-7b-instruct</td>\n",
       "      <td>q4km</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.496869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tokyotech-llm</td>\n",
       "      <td>Swallow-MX-8x7b-NVE-v0.1</td>\n",
       "      <td>q4km</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.989899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           family                           model_name   variant  grade_avg  \\\n",
       "0        SakanaAI                    EvoLLM-JP-A-v1-7B  original       2.09   \n",
       "1        SakanaAI                    EvoLLM-JP-A-v1-7B      q4km       2.00   \n",
       "2        SakanaAI                     EvoLLM-JP-v1-10B  original       2.43   \n",
       "3        SakanaAI                      EvoLLM-JP-v1-7B  original       2.83   \n",
       "4        SakanaAI                      EvoLLM-JP-v1-7B      q4km       2.53   \n",
       "5         Xwin-LM                     Xwin-LM-13B-V0.1  original       2.43   \n",
       "6         Xwin-LM                     Xwin-LM-13B-V0.1      q4km       2.54   \n",
       "7         Xwin-LM                      Xwin-LM-7B-V0.1  original       2.32   \n",
       "8         Xwin-LM                      Xwin-LM-7B-V0.1      q4km       1.96   \n",
       "9      cyberagent                        calm2-7b-chat  original       2.26   \n",
       "10     cyberagent                        calm2-7b-chat      q4km       2.58   \n",
       "11          elyza  ELYZA-japanese-Llama-2-13b-instruct  original       2.57   \n",
       "12          elyza  ELYZA-japanese-Llama-2-13b-instruct      q4km       2.46   \n",
       "13          elyza   ELYZA-japanese-Llama-2-7b-instruct  original       2.30   \n",
       "14          elyza   ELYZA-japanese-Llama-2-7b-instruct      q4km       2.20   \n",
       "15    karakuri-ai            karakuri-lm-70b-chat-v0.1      q4km       2.98   \n",
       "16          rinna                        youri-7b-chat  original       1.93   \n",
       "17          rinna                        youri-7b-chat      q4km       1.81   \n",
       "18    stabilityai   japanese-stablelm-instruct-beta-7b  original       1.28   \n",
       "19    stabilityai   japanese-stablelm-instruct-beta-7b      q4km       1.49   \n",
       "20  tokyotech-llm                 Swallow-13b-instruct  original       2.12   \n",
       "21  tokyotech-llm                 Swallow-13b-instruct      q4km       1.84   \n",
       "22  tokyotech-llm                  Swallow-7b-instruct  original       1.91   \n",
       "23  tokyotech-llm                  Swallow-7b-instruct      q4km       1.91   \n",
       "24  tokyotech-llm             Swallow-MX-8x7b-NVE-v0.1      q4km       2.30   \n",
       "\n",
       "    grade_variance  \n",
       "0         1.921111  \n",
       "1         1.696970  \n",
       "2         1.803131  \n",
       "3         2.283939  \n",
       "4         2.110202  \n",
       "5         1.661717  \n",
       "6         1.907475  \n",
       "7         1.654141  \n",
       "8         1.351919  \n",
       "9         1.709495  \n",
       "10        1.862222  \n",
       "11        2.085960  \n",
       "12        1.806465  \n",
       "13        1.848485  \n",
       "14        1.636364  \n",
       "15        2.161212  \n",
       "16        1.722323  \n",
       "17        1.428182  \n",
       "18        0.648081  \n",
       "19        0.959495  \n",
       "20        1.763232  \n",
       "21        1.408485  \n",
       "22        1.335253  \n",
       "23        1.496869  \n",
       "24        1.989899  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the average and variance of grades grouped by family, model_name, and variant\n",
    "df_summary_stats = df_raw_results.groupby(['family', 'model_name', 'variant'])['grade'].agg(['mean', 'var']).reset_index()\n",
    "\n",
    "# Rename the columns to match your requirements\n",
    "df_summary_stats.rename(columns={'mean': 'grade_avg', 'var': 'grade_variance'}, inplace=True)\n",
    "\n",
    "df_summary_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312b0a2f-deb6-4e09-863a-be8b23da64dc",
   "metadata": {},
   "source": [
    "variant を横持ちするようにピボットする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b010767e-2a88-433d-a554-5016959c5e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>model_name</th>\n",
       "      <th>grade_avg_original</th>\n",
       "      <th>grade_avg_q4km</th>\n",
       "      <th>grade_variance_original</th>\n",
       "      <th>grade_variance_q4km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SakanaAI</td>\n",
       "      <td>EvoLLM-JP-A-v1-7B</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.921111</td>\n",
       "      <td>1.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SakanaAI</td>\n",
       "      <td>EvoLLM-JP-v1-10B</td>\n",
       "      <td>2.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.803131</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SakanaAI</td>\n",
       "      <td>EvoLLM-JP-v1-7B</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.283939</td>\n",
       "      <td>2.110202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xwin-LM</td>\n",
       "      <td>Xwin-LM-13B-V0.1</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.54</td>\n",
       "      <td>1.661717</td>\n",
       "      <td>1.907475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xwin-LM</td>\n",
       "      <td>Xwin-LM-7B-V0.1</td>\n",
       "      <td>2.32</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.654141</td>\n",
       "      <td>1.351919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cyberagent</td>\n",
       "      <td>calm2-7b-chat</td>\n",
       "      <td>2.26</td>\n",
       "      <td>2.58</td>\n",
       "      <td>1.709495</td>\n",
       "      <td>1.862222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>elyza</td>\n",
       "      <td>ELYZA-japanese-Llama-2-13b-instruct</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.085960</td>\n",
       "      <td>1.806465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>elyza</td>\n",
       "      <td>ELYZA-japanese-Llama-2-7b-instruct</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.848485</td>\n",
       "      <td>1.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>karakuri-ai</td>\n",
       "      <td>karakuri-lm-70b-chat-v0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.161212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rinna</td>\n",
       "      <td>youri-7b-chat</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1.722323</td>\n",
       "      <td>1.428182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stabilityai</td>\n",
       "      <td>japanese-stablelm-instruct-beta-7b</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.648081</td>\n",
       "      <td>0.959495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tokyotech-llm</td>\n",
       "      <td>Swallow-13b-instruct</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.763232</td>\n",
       "      <td>1.408485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tokyotech-llm</td>\n",
       "      <td>Swallow-7b-instruct</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.335253</td>\n",
       "      <td>1.496869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tokyotech-llm</td>\n",
       "      <td>Swallow-MX-8x7b-NVE-v0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.989899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           family                           model_name  grade_avg_original  \\\n",
       "0        SakanaAI                    EvoLLM-JP-A-v1-7B                2.09   \n",
       "1        SakanaAI                     EvoLLM-JP-v1-10B                2.43   \n",
       "2        SakanaAI                      EvoLLM-JP-v1-7B                2.83   \n",
       "3         Xwin-LM                     Xwin-LM-13B-V0.1                2.43   \n",
       "4         Xwin-LM                      Xwin-LM-7B-V0.1                2.32   \n",
       "5      cyberagent                        calm2-7b-chat                2.26   \n",
       "6           elyza  ELYZA-japanese-Llama-2-13b-instruct                2.57   \n",
       "7           elyza   ELYZA-japanese-Llama-2-7b-instruct                2.30   \n",
       "8     karakuri-ai            karakuri-lm-70b-chat-v0.1                 NaN   \n",
       "9           rinna                        youri-7b-chat                1.93   \n",
       "10    stabilityai   japanese-stablelm-instruct-beta-7b                1.28   \n",
       "11  tokyotech-llm                 Swallow-13b-instruct                2.12   \n",
       "12  tokyotech-llm                  Swallow-7b-instruct                1.91   \n",
       "13  tokyotech-llm             Swallow-MX-8x7b-NVE-v0.1                 NaN   \n",
       "\n",
       "    grade_avg_q4km  grade_variance_original  grade_variance_q4km  \n",
       "0             2.00                 1.921111             1.696970  \n",
       "1              NaN                 1.803131                  NaN  \n",
       "2             2.53                 2.283939             2.110202  \n",
       "3             2.54                 1.661717             1.907475  \n",
       "4             1.96                 1.654141             1.351919  \n",
       "5             2.58                 1.709495             1.862222  \n",
       "6             2.46                 2.085960             1.806465  \n",
       "7             2.20                 1.848485             1.636364  \n",
       "8             2.98                      NaN             2.161212  \n",
       "9             1.81                 1.722323             1.428182  \n",
       "10            1.49                 0.648081             0.959495  \n",
       "11            1.84                 1.763232             1.408485  \n",
       "12            1.91                 1.335253             1.496869  \n",
       "13            2.30                      NaN             1.989899  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, ensure the 'grade_avg' is present in your DataFrame\n",
    "# Assuming 'summary_stats' contains the necessary average grades\n",
    "df_summary_wide = df_summary_stats.pivot_table(\n",
    "    index=['family', 'model_name'],  # Columns to keep as-is\n",
    "    columns='variant',  # Column to pivot\n",
    "    values=['grade_avg', 'grade_variance'],  # The values to use when pivoting\n",
    "    aggfunc='first'  # How to aggregate when pivoting, 'first' simply takes the first value found\n",
    ")\n",
    "\n",
    "# Flatten the columns and rename as needed\n",
    "df_summary_wide.columns = [f'{metric}_{variant}' for metric, variant in df_summary_wide.columns]\n",
    "df_summary_wide.reset_index(inplace=True)\n",
    "\n",
    "df_summary_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "695017e2-6f1f-4c17-8e5d-23daad7215d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",family,model_name,grade_avg_original,grade_avg_q4km,grade_variance_original,grade_variance_q4km\n",
      "0,SakanaAI,EvoLLM-JP-A-v1-7B,2.09,2.0,1.9211111111111108,1.6969696969696966\n",
      "1,SakanaAI,EvoLLM-JP-v1-10B,2.43,,1.8031313131313127,\n",
      "2,SakanaAI,EvoLLM-JP-v1-7B,2.83,2.53,2.2839393939393946,2.1102020202020193\n",
      "3,Xwin-LM,Xwin-LM-13B-V0.1,2.43,2.54,1.6617171717171726,1.9074747474747487\n",
      "4,Xwin-LM,Xwin-LM-7B-V0.1,2.32,1.96,1.6541414141414144,1.351919191919192\n",
      "5,cyberagent,calm2-7b-chat,2.26,2.58,1.7094949494949496,1.862222222222222\n",
      "6,elyza,ELYZA-japanese-Llama-2-13b-instruct,2.57,2.46,2.085959595959596,1.8064646464646466\n",
      "7,elyza,ELYZA-japanese-Llama-2-7b-instruct,2.3,2.2,1.848484848484848,1.6363636363636371\n",
      "8,karakuri-ai,karakuri-lm-70b-chat-v0.1,,2.98,,2.1612121212121203\n",
      "9,rinna,youri-7b-chat,1.93,1.81,1.7223232323232323,1.428181818181818\n",
      "10,stabilityai,japanese-stablelm-instruct-beta-7b,1.28,1.49,0.6480808080808079,0.9594949494949492\n",
      "11,tokyotech-llm,Swallow-13b-instruct,2.12,1.84,1.7632323232323233,1.4084848484848482\n",
      "12,tokyotech-llm,Swallow-7b-instruct,1.91,1.91,1.335252525252525,1.4968686868686873\n",
      "13,tokyotech-llm,Swallow-MX-8x7b-NVE-v0.1,,2.3,,1.9898989898989894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_summary_wide.to_csv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acda8f9-5674-4ead-a695-4e42e2518adf",
   "metadata": {},
   "source": [
    "出力された CSV を Excel にコピーし、棒グラフに加工する。\n",
    "\n",
    "（Matplotlib でもよいが、Excel のほうが加工しやすい...）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
